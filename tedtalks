import pandas as pd

#read in TedTalk dataframe
ted_df = pd.read_csv('TED_Talk_1_copy.csv.', delimiter = ',', encoding = 'utf-8'
ted_df
#get an idea of how many vidoes are in each category
ted_df['video_type_name'].value.counts()

Make separate dataframe for TEDx Talks

#make a filter for only TEDx Talks in output
tedx_only_filter = ted_df['video_type_name'] == 'TEDx Talk'

#save TEDx only output as a separate dataframe
tedx_only_df = ted_df[tedx_only_filter].copy()
tedx_only_df
tedx_titles = tedx_only_df['talk_name']
#check to see how many NaN cells there are in the transcript column. Not every talk has a transcript saved.
tedx_only_df['transcript'].isna().value_counts()
#drop rows with NaN in the transcript column
tedx_only_df.dropna(subset =['transcript'], inplace=True)
#filter by language
language_filter = tedx_only_df['language'] == 'en'
#save TEDx Talk dataframe with only English TEDx Talks
tedx_only_df = tedx_only_df[language_filter].copy()
tedx_only_df
#just to get a peek at our TEDx Talk, English only dataframe
tedx_only_df.describe(include='all')

!pip install little_mallet_wrapper
!pip install seaborn

import little_mallet_wrapper
import glob
from pathlib import Path
!!pip install git+https://github.com/maria-antoniak/little-mallet-wrapper.git
import random
pd.options.display.max_colwidth = 100

#read transcripts as strings
tedx_only_df['transcript'] = tedx_only_df['transcript'].astype(str)
#pre-processed transcripts as training data
training_data_tedx = [little_mallet_wrapper.process_string(text, numbers='remove') for text in tedx_only_df['transcript']]
path_to_mallet = 'mallet/bin/mallet'
num_topics = 20

#Change to your desired output directory
output_directory_path = 'tedx-talk-output'

#No need to change anything below here
Path(f"{output_directory_path}").mkdir(parents=True, exist_ok=True)

path_to_training_data           = f"{output_directory_path}/training.txt"
path_to_formatted_training_data = f"{output_directory_path}/mallet.training"
path_to_model                   = f"{output_directory_path}/mallet.model.{str(num_topics)}"
path_to_topic_keys              = f"{output_directory_path}/mallet.topic_keys.{str(num_topics)}"
path_to_topic_distributions     = f"{output_directory_path}/mallet.topic_distributions.{str(num_topics)}"

little_mallet_wrapper.quick_train_topic_model(path_to_mallet,
                                             output_directory_path,
                                             num_topics,
                                             training_data_tedx)
                                             
                                             #get 20 different topics for TEDx Talks

from IPython.display import Markdown, display
import re

topics_tedx = little_mallet_wrapper.load_topic_keys(path_to_topic_keys)
topic_distributions = little_mallet_wrapper.load_topic_distributions(path_to_topic_distributions)

def make_md(string):
    """A function that transforms string data into Markdown
    so it can be nicely formatted with bolding and emojis
    """
    display(Markdown(str(string)))

def get_top_docs(docs, topic_distributions, topic_index, n=5): 
    
    """A function that shows the top documents for a given set of topic distributions
    and a specific topic number
    """
    
    sorted_data = sorted([(_distribution[topic_index], _document) for _distribution, _document in zip(topic_distributions, docs)], reverse=True)
    topic_words = topics_tedx[topic_index]
    make_md(f"### ✨Topic {topic_index}✨\n\n{topic_words}\n\n---")
    
    for probability, doc in sorted_data[:n]:
        # Make topic words bolded
        for word in topic_words:
            if word in doc.lower():
                doc = re.sub(f"\\b{word}\\b", f"**{word}**", doc, re.IGNORECASE)
        make_md(f'✨  \n**Topic Probability**: {probability}  \n**Document**: {doc}\n\n')
        
#testing out topic modelling with training data

for number, topic in enumerate(topics_tedx):
    print(f"✨Topic {number}✨\n\n{topic}\n")
    
#get 5 top docs for Topic 1
get_top_docs(training_data_tedx, topic_distributions, topic_index=1, n=5)

#define variables to run the topic modelling without any preprocessing
tedx_titles = tedx_only_df['talk_name']
original_tedx_transcripts = tedx_only_df['transcript']

Make category names for topics from TEDx Talks

get_top_docs(original_tedx_transcripts, topic_distributions, topic_index=1, n=5)
get_top_docs(tedx_titles, topic_distributions, topic_index=1, n=5)

get_top_docs(original_tedx_transcripts, topic_distributions, topic_index=0, n=5)
get_top_docs(tedx_titles, topic_distributions, topic_index=0, n=5)

get_top_docs(original_tedx_transcripts, topic_distributions, topic_index=2, n=5)
get_top_docs(tedx_titles, topic_distributions, topic_index=2, n=5)

get_top_docs(original_tedx_transcripts, topic_distributions, topic_index=3, n=5)
get_top_docs(tedx_titles, topic_distributions, topic_index=3, n=5)

get_top_docs(original_tedx_transcripts, topic_distributions, topic_index=4, n=5)
get_top_docs(tedx_titles, topic_distributions, topic_index=4, n=5)

get_top_docs(original_tedx_transcripts, topic_distributions, topic_index=5, n=5)
get_top_docs(tedx_titles, topic_distributions, topic_index=5, n=5)

get_top_docs(original_tedx_transcripts, topic_distributions, topic_index=6, n=5)
get_top_docs(tedx_titles, topic_distributions, topic_index=6, n=5)

get_top_docs(original_tedx_transcripts, topic_distributions, topic_index=7, n=5)
get_top_docs(tedx_titles, topic_distributions, topic_index=7, n=5)

get_top_docs(original_tedx_transcripts, topic_distributions, topic_index=8, n=5)
get_top_docs(tedx_titles, topic_distributions, topic_index=8, n=5)

get_top_docs(original_tedx_transcripts, topic_distributions, topic_index=9, n=5)
get_top_docs(tedx_titles, topic_distributions, topic_index=9, n=5)

get_top_docs(original_tedx_transcripts, topic_distributions, topic_index=10, n=5)
get_top_docs(tedx_titles, topic_distributions, topic_index=10, n=5)

get_top_docs(original_tedx_transcripts, topic_distributions, topic_index=11, n=5)
get_top_docs(tedx_titles, topic_distributions, topic_index=11, n=5)

get_top_docs(original_tedx_transcripts, topic_distributions, topic_index=12, n=5)
get_top_docs(tedx_titles, topic_distributions, topic_index=12, n=5)

get_top_docs(original_tedx_transcripts, topic_distributions, topic_index=13, n=5)
get_top_docs(tedx_titles, topic_distributions, topic_index=13, n=5)

get_top_docs(original_tedx_transcripts, topic_distributions, topic_index=14, n=5)
get_top_docs(tedx_titles, topic_distributions, topic_index=14, n=5)

get_top_docs(original_tedx_transcripts, topic_distributions, topic_index=15, n=5)
get_top_docs(tedx_titles, topic_distributions, topic_index=15, n=5)

get_top_docs(original_tedx_transcripts, topic_distributions, topic_index=16, n=5)
get_top_docs(tedx_titles, topic_distributions, topic_index=16, n=5)

get_top_docs(original_tedx_transcripts, topic_distributions, topic_index=17, n=5)
get_top_docs(tedx_titles, topic_distributions, topic_index=17, n=5)

get_top_docs(original_tedx_transcripts, topic_distributions, topic_index=18, n=5)
get_top_docs(tedx_titles, topic_distributions, topic_index=18, n=5)

get_top_docs(original_tedx_transcripts, topic_distributions, topic_index=19, n=5)
get_top_docs(tedx_titles, topic_distributions, topic_index=19, n=5)

#dataframe fro TED Stage Talks

ted_stage_only_filter = ted_df['video_type_name'] == 'TED Stage Talk'
ted_stage_only_df = ted_df[ted_stage_only_filter]
ted_stage_only_df = ted_df[ted_stage_only_filter].copy()
ted_stage_only_df

#check to see how many NaN cells there are in the transcript column for TED Stage Talk. Not every talk has a transcript saved.
ted_stage_only_df['transcript'].isna().value_counts()

#drop rows with NaN in the transcript column
ted_stage_only_df.dropna(subset =['transcript'], inplace=True)

#filter by language
language_filter = ted_stage_only_df['language'] == 'en'

#save TED Stage Talk dataframe with only English TED Stage Talks
ted_stage_only_df = ted_stage_only_df[language_filter].copy()
ted_stage_only_df

#check to see that only the English lg TED Stage Talks have been included
ted_stage_only_df['language'].describe(include='all')

Topic modeling for English-only TED Stage Talks
#read transcripts as strings
ted_stage_only_df['transcript'] = ted_stage_only_df['transcript'].astype(str)

#pre-processed transcripts as training data
training_data_ted_stage = [little_mallet_wrapper.process_string(text, numbers='remove') for text in ted_stage_only_df['transcript']]

path_to_mallet = 'mallet/bin/mallet'
num_topics = 20

#Change to your desired output directory
output_directory_path = 'ted-stage-talk-output'

#No need to change anything below here
Path(f"{output_directory_path}").mkdir(parents=True, exist_ok=True)

path_to_training_data           = f"{output_directory_path}/training.txt"
path_to_formatted_training_data = f"{output_directory_path}/mallet.training"
path_to_model                   = f"{output_directory_path}/mallet.model.{str(num_topics)}"
path_to_topic_keys              = f"{output_directory_path}/mallet.topic_keys.{str(num_topics)}"
path_to_topic_distributions     = f"{output_directory_path}/mallet.topic_distributions.{str(num_topics)}"

little_mallet_wrapper.quick_train_topic_model(path_to_mallet,
                                             output_directory_path,
                                             num_topics,
                                             training_data_ted_stage)
                                             
ted_stage_titles = ted_stage_only_df['talk_name']
original_ted_stage_transcripts = ted_stage_only_df['transcript']

from IPython.display import Markdown, display
import re

topics_ted_stage = little_mallet_wrapper.load_topic_keys(path_to_topic_keys)
topic_distributions = little_mallet_wrapper.load_topic_distributions(path_to_topic_distributions)

def make_md(string):
    """A function that transforms string data into Markdown
    so it can be nicely formatted with bolding and emojis
    """
    display(Markdown(str(string)))

def get_top_docs(docs, topic_distributions, topic_index, n=5): #redefine this function to show multiple parameters (ie. the talk_name and the transcript at the same time)
    
    """A function that shows the top documents for a given set of topic distributions
    and a specific topic number
    """
    
    sorted_data = sorted([(_distribution[topic_index], _document) for _distribution, _document in zip(topic_distributions, docs)], reverse=True)
    topic_words = topics_ted_stage[topic_index]
    make_md(f"### ✨Topic {topic_index}✨\n\n{topic_words}\n\n---")
    
    for probability, doc in sorted_data[:n]:
        # Make topic words bolded
        for word in topic_words:
            if word in doc.lower():
                doc = re.sub(f"\\b{word}\\b", f"**{word}**", doc, re.IGNORECASE)
        make_md(f'✨  \n**Topic Probability**: {probability}  \n**Document**: {doc}\n\n')
        
        #testing out topic modelling of TED Stage Talks with training data

for number, topic in enumerate(topics_ted_stage):
    print(f"✨Topic {number}✨\n\n{topic}\n")
    
#get 5 top docs for Topic 1
get_top_docs(training_data_ted_stage, topic_distributions, topic_index=1, n=5)

#get top docs for Topic 1 on Ted Stage Talks (not pre-preprocessed)
get_top_docs(original_ted_stage_transcripts, topic_distributions, topic_index=1, n=5)

get_top_docs(ted_stage_titles, topic_distributions, topic_index=1, n=5)

categorize topics for English-only TED Stage Talks

get_top_docs(original_ted_stage_transcripts, topic_distributions, topic_index=8, n=10)
get_top_docs(tedx_titles, topic_distributions, topic_index=8, n=10)

get_top_docs(original_ted_stage_transcripts, topic_distributions, topic_index=13, n=5)
get_top_docs(ted_stage_titles, topic_distributions, topic_index=13, n=5)

get_top_docs(original_ted_stage_transcripts, topic_distributions, topic_index=19, n=5)
get_top_docs(ted_stage_titles, topic_distributions, topic_index=19, n=5)

get_top_docs(original_ted_stage_transcripts, topic_distributions, topic_index=18, n=5)
get_top_docs(ted_stage_titles, topic_distributions, topic_index=18, n=5)

get_top_docs(original_ted_stage_transcripts, topic_distributions, topic_index=17, n=5)
get_top_docs(ted_stage_titles, topic_distributions, topic_index=17, n=5)

get_top_docs(original_ted_stage_transcripts, topic_distributions, topic_index=16, n=5)
get_top_docs(ted_stage_titles, topic_distributions, topic_index=16, n=5)

get_top_docs(original_ted_stage_transcripts, topic_distributions, topic_index=15, n=5)
get_top_docs(ted_stage_titles, topic_distributions, topic_index=15, n=5)

get_top_docs(original_ted_stage_transcripts, topic_distributions, topic_index=14, n=5)
get_top_docs(ted_stage_titles, topic_distributions, topic_index=14, n=5)

get_top_docs(original_ted_stage_transcripts, topic_distributions, topic_index=12, n=5)
get_top_docs(ted_stage_titles, topic_distributions, topic_index=12, n=5)

get_top_docs(original_ted_stage_transcripts, topic_distributions, topic_index=11, n=5)
get_top_docs(ted_stage_titles, topic_distributions, topic_index=11, n=5)

get_top_docs(original_ted_stage_transcripts, topic_distributions, topic_index=10, n=5)
get_top_docs(ted_stage_titles, topic_distributions, topic_index=10, n=5)

get_top_docs(original_ted_stage_transcripts, topic_distributions, topic_index=9, n=5)
get_top_docs(ted_stage_titles, topic_distributions, topic_index=9, n=5)

get_top_docs(original_ted_stage_transcripts, topic_distributions, topic_index=7, n=5)
get_top_docs(ted_stage_titles, topic_distributions, topic_index=7, n=5)

get_top_docs(original_ted_stage_transcripts, topic_distributions, topic_index=6, n=5)
get_top_docs(ted_stage_titles, topic_distributions, topic_index=6, n=5)

get_top_docs(original_ted_stage_transcripts, topic_distributions, topic_index=5, n=5)
get_top_docs(ted_stage_titles, topic_distributions, topic_index=5, n=5)

get_top_docs(original_ted_stage_transcripts, topic_distributions, topic_index=4, n=5)
get_top_docs(ted_stage_titles, topic_distributions, topic_index=4, n=5)

get_top_docs(original_ted_stage_transcripts, topic_distributions, topic_index=3, n=5)
get_top_docs(ted_stage_titles, topic_distributions, topic_index=3, n=5)

get_top_docs(original_ted_stage_transcripts, topic_distributions, topic_index=2, n=5)
get_top_docs(ted_stage_titles, topic_distributions, topic_index=2, n=5)

get_top_docs(original_ted_stage_transcripts, topic_distributions, topic_index=1, n=5)
get_top_docs(ted_stage_titles, topic_distributions, topic_index=1, n=5)

get_top_docs(original_ted_stage_transcripts, topic_distributions, topic_index=0, n=5)
get_top_docs(ted_stage_titles, topic_distributions, topic_index=0, n=5)

Word Shift Graph comparing TED Stage and TEDx Talk transcripts

from collections import Counter
import re

stopwords = ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'us', 'didn', 'ourselves', 'you', 'your', 'yours',
 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', 'her', 'hers',
 'herself', 'it', 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves',
 'what', 'which', 'who', 'whom', 'this', 'that', 'these', 'those', 'am', 'is', 'are',
 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does',
 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until',
 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into',
 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down',
 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here',
 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more',
 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'should', 'could', 'would', 'may', 'might', 'can', 'ted', 'wasn'
 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', 'should', 'now', 've', 'll', 'amp', 're', 'also', 'way', 'm', '0000', 'ca', '000', '00', '0']
 
 def tokenize_words(text):
    lowercase_text = text.lower()
    split_words = re.split("\W+", lowercase_text)
    meaningful_words = [word for word in split_words if word not in stopwords] 
    return meaningful_words
    
tedx_only_df['transcript'].to_list()

ted_stage_only_df['transcript'].to_list()

tedx_transcript = tedx_only_df['transcript'].to_list()

ted_stage_transcript = ted_stage_only_df['transcript'].to_list()

for transcript_x in tedx_transcript:
    transcript_x = tokenize_words(transcript_x)
    print(transcript_x)
    
for transcript_stage in ted_stage_transcript:
    transcript_stage = tokenize_words(transcript_stage)
    print(transcript_stage)
    
    #not sure why this isn't taking out the stopwords
    
tedx_counts = Counter()

for transcript_x in tedx_transcript:
    words = tokenize_words(transcript_x)
    tedx_counts.update(words)
    
len(ted_stage_transcript)

ted_stage_counts = Counter()

for transcript_stage in ted_stage_transcript:
    words = tokenize_words(transcript_stage)
    ted_stage_counts.update(words)
    
tedx_counts

ted_stage_counts

!pip install shifterator

import shifterator as sh

import warnings
warnings.filterwarnings("ignore")

proportion_shift = sh.ProportionShift(type2freq_1 = tedx_counts,
                                        type2freq_2= ted_stage_counts)

proportion_shift.get_shift_graph(system_names = ['TEDx Talks', 'TED Stage Talks'],  width=15, height=15, cumulative_inset=False,  top_n = 40)

